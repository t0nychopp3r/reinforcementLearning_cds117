{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning - Resource Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kudos to:\n",
    "\n",
    "https://www.gymlibrary.dev/content/environment_creation/\n",
    "\n",
    "https://www.youtube.com/watch?v=bD6V3rcr_54&ab_channel=NicholasRenotte \n",
    "\n",
    "Version 1.0:\n",
    "\n",
    "- Added negative Reward when moving around, Maximum of 100 Steps possible, then set Episode to done\n",
    "- Add a Reward if near the Target\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Gym Environment for Resource Manager\n",
    "#The environment is a 2D grid with 4 possible actions: up, down, left, right\n",
    "#The agent can move in any direction but cannot move outside the grid\n",
    "\n",
    "class ResourceManagerEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "\n",
    "    def __init__(self, grid_size=10, render_mode=None):\n",
    "\n",
    "        #initialize the reward\n",
    "        self.total_reward = 0\n",
    "\n",
    "        #Define Grid Size\n",
    "        self.grid_size = grid_size\n",
    "        self.window_size = 500\n",
    "\n",
    "        #Action Space:\n",
    "        #0: Right, 1: up, 2: left, 3: down\n",
    "\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "        #Map the action to the corresponding movement\n",
    "        self.action_to_direction = {\n",
    "            0: np.array([1, 0]),\n",
    "            1: np.array([0, 1]),\n",
    "            2: np.array([-1, 0]),\n",
    "            3: np.array([0, -1]),\n",
    "        }\n",
    "\n",
    "        #Observation Space:\n",
    "        #The observation space is a 2D grid with the agent's position marked as 1\n",
    "        #and the rest of the grid marked as 0\n",
    "\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(grid_size, grid_size), dtype=np.float32)\n",
    "        self.reset()\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "\n",
    "\n",
    "\n",
    "    #Needed for Environment Reset\n",
    "    def reset(self, seed=None):\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        #Choose the agent's initial position at random\n",
    "        self.agent_position = self.np_random.integers(low=0, high=self.grid_size, size=(2,))\n",
    "\n",
    "        #Set the target position at random until it is different from the agent's position\n",
    "        self.target_position = self.agent_position\n",
    "        while np.all(self.target_position == self.agent_position):\n",
    "            self.target_position = self.np_random.integers(low=0, high=self.grid_size, size=(2,))\n",
    "\n",
    "        self.total_reward = 0\n",
    "\n",
    "        observation = self.get_obs()\n",
    "        info = self.get_info()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render_frame()\n",
    "\n",
    "        return observation, info\n",
    "    \n",
    "    def get_obs(self):\n",
    "        #Initialize observation\n",
    "        observation = np.zeros((self.grid_size, self.grid_size), dtype=np.float32)\n",
    "\n",
    "        #Mark the agent's position\n",
    "        observation[tuple(self.agent_position)] = 1\n",
    "        return observation\n",
    "    \n",
    "    def get_info(self):\n",
    "        #Initialize info\n",
    "        info = {\n",
    "            'agent_position': self.agent_position,\n",
    "            'target_position': self.target_position,\n",
    "            'total_reward': self.total_reward\n",
    "        }\n",
    "        return info\n",
    "    \n",
    "    def step(self, action):\n",
    "\n",
    "        # ***** Move around the grid *****\n",
    "\n",
    "        #store the agent's position before taking a step\n",
    "        original_position = np.copy(self.agent_position)\n",
    "        #choose a direction\n",
    "        direction = self.action_to_direction[action]\n",
    "        #Move the agent in that direction\n",
    "        self.agent_position = np.clip(\n",
    "            self.agent_position + direction,\n",
    "            0,\n",
    "            self.grid_size - 1\n",
    "        )\n",
    "        #check if the agent's position has changed\n",
    "        position_changed = not np.all(self.agent_position == original_position)\n",
    "\n",
    "        #define when done\n",
    "        done = np.all(self.agent_position == self.target_position)\n",
    "\n",
    "        # ***** Reward Function *****\n",
    "\n",
    "        #calculate Manhatten distance between agent and target\n",
    "        distance_to_target = np.abs(self.agent_position[0] - self.target_position[0]) + np.abs(self.agent_position[1] - self.target_position[1])\n",
    "\n",
    "\n",
    "        if done:\n",
    "            reward = 0  #the agent has reached the target\n",
    "        elif position_changed:\n",
    "            reward = -1  #the agent has taken a step\n",
    "        else:\n",
    "            #idea: implement already a reward if the agent did not move\n",
    "            reward = -10  #the agent didn't move, so give a -10 reward\n",
    "        \n",
    "        #give reward to the agent if it is close to the target\n",
    "        if distance_to_target == 1:\n",
    "            reward += 2  # +2 reward when immediately around the target\n",
    "        elif distance_to_target <= 4:\n",
    "            reward += 1  # +1 reward when within 16 fields around the target\n",
    "\n",
    "        self.total_reward += reward\n",
    "\n",
    "        #stop the episode when reward is -100\n",
    "        if self.total_reward == -100:\n",
    "            done = True\n",
    "            self.reset()\n",
    "\n",
    "\n",
    "        observation = self.get_obs()\n",
    "        info = self.get_info()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render_frame()\n",
    "\n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def render(self):\n",
    "            if self.render_mode == \"rgb_array\":\n",
    "                return self.render_frame()\n",
    "    \n",
    "    def render_frame(self):\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
    "        if self.clock is None and self.render_mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        pix_square_size = (\n",
    "            self.window_size / self.grid_size\n",
    "        )  # The size of a single grid square in pixels\n",
    "        # First we draw the target\n",
    "        pygame.draw.rect(\n",
    "            canvas,\n",
    "            (255, 0, 0),\n",
    "            pygame.Rect(\n",
    "                pix_square_size * self.target_position,\n",
    "                (pix_square_size, pix_square_size),\n",
    "            ),\n",
    "        )\n",
    "        # Now we draw the agent\n",
    "        pygame.draw.circle(\n",
    "            canvas,\n",
    "            (0, 0, 255),\n",
    "            (self.agent_position + 0.5) * pix_square_size,\n",
    "            pix_square_size / 3,\n",
    "        )\n",
    "        # Finally, add some gridlines\n",
    "        for x in range(self.grid_size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (0, pix_square_size * x),\n",
    "                (self.window_size, pix_square_size * x),\n",
    "                width=3,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (pix_square_size * x, 0),\n",
    "                (pix_square_size * x, self.window_size),\n",
    "                width=3,\n",
    "            )\n",
    "        if self.render_mode == \"human\":\n",
    "            # The following line copies our drawings from `canvas` to the visible window\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "            # We need to ensure that human-rendering occurs at the predefined framerate.\n",
    "            # The following line will automatically add a delay to keep the framerate stable.\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:  # rgb_array\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n",
    "        \n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "        self.window = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "register(\n",
    "    id='Resource-Manager-v10',\n",
    "    entry_point='ResourceManager_v1_0.ipynb:ResourceManagerEnv',\n",
    "    max_episode_steps=300,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 10\n",
    "\n",
    "env = ResourceManagerEnv(grid_size=grid_size, render_mode=\"human\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent position: [5 1], Target position: [0 2], Total reward: -1, Step reward: -1, Episode: 0\n",
      "Agent position: [6 1], Target position: [0 2], Total reward: -2, Step reward: -1, Episode: 0\n",
      "Agent position: [5 1], Target position: [0 2], Total reward: -3, Step reward: -1, Episode: 0\n",
      "Agent position: [4 1], Target position: [0 2], Total reward: -4, Step reward: -1, Episode: 0\n",
      "Agent position: [3 1], Target position: [0 2], Total reward: -4, Step reward: 0, Episode: 0\n",
      "Agent position: [4 1], Target position: [0 2], Total reward: -5, Step reward: -1, Episode: 0\n",
      "Agent position: [5 1], Target position: [0 2], Total reward: -6, Step reward: -1, Episode: 0\n",
      "Agent position: [5 0], Target position: [0 2], Total reward: -7, Step reward: -1, Episode: 0\n",
      "Agent position: [5 1], Target position: [0 2], Total reward: -8, Step reward: -1, Episode: 0\n",
      "Agent position: [4 1], Target position: [0 2], Total reward: -9, Step reward: -1, Episode: 0\n",
      "Agent position: [3 1], Target position: [0 2], Total reward: -9, Step reward: 0, Episode: 0\n",
      "Agent position: [3 0], Target position: [0 2], Total reward: -10, Step reward: -1, Episode: 0\n",
      "Agent position: [2 0], Target position: [0 2], Total reward: -10, Step reward: 0, Episode: 0\n",
      "Agent position: [3 0], Target position: [0 2], Total reward: -11, Step reward: -1, Episode: 0\n",
      "Agent position: [4 0], Target position: [0 2], Total reward: -12, Step reward: -1, Episode: 0\n",
      "Agent position: [5 0], Target position: [0 2], Total reward: -13, Step reward: -1, Episode: 0\n",
      "Agent position: [5 1], Target position: [0 2], Total reward: -14, Step reward: -1, Episode: 0\n",
      "Agent position: [5 0], Target position: [0 2], Total reward: -15, Step reward: -1, Episode: 0\n",
      "Agent position: [4 0], Target position: [0 2], Total reward: -16, Step reward: -1, Episode: 0\n",
      "Agent position: [5 0], Target position: [0 2], Total reward: -17, Step reward: -1, Episode: 0\n",
      "Agent position: [6 0], Target position: [0 2], Total reward: -18, Step reward: -1, Episode: 0\n",
      "Agent position: [6 0], Target position: [0 2], Total reward: -28, Step reward: -10, Episode: 0\n",
      "Agent position: [6 0], Target position: [0 2], Total reward: -38, Step reward: -10, Episode: 0\n",
      "Agent position: [5 0], Target position: [0 2], Total reward: -39, Step reward: -1, Episode: 0\n",
      "Agent position: [5 0], Target position: [0 2], Total reward: -49, Step reward: -10, Episode: 0\n",
      "Agent position: [5 0], Target position: [0 2], Total reward: -59, Step reward: -10, Episode: 0\n",
      "Agent position: [6 0], Target position: [0 2], Total reward: -60, Step reward: -1, Episode: 0\n",
      "Agent position: [6 0], Target position: [0 2], Total reward: -70, Step reward: -10, Episode: 0\n",
      "Agent position: [6 1], Target position: [0 2], Total reward: -71, Step reward: -1, Episode: 0\n",
      "Agent position: [5 1], Target position: [0 2], Total reward: -72, Step reward: -1, Episode: 0\n",
      "Agent position: [5 0], Target position: [0 2], Total reward: -73, Step reward: -1, Episode: 0\n",
      "Agent position: [5 1], Target position: [0 2], Total reward: -74, Step reward: -1, Episode: 0\n",
      "Agent position: [6 1], Target position: [0 2], Total reward: -75, Step reward: -1, Episode: 0\n",
      "Agent position: [6 2], Target position: [0 2], Total reward: -76, Step reward: -1, Episode: 0\n",
      "Agent position: [6 1], Target position: [0 2], Total reward: -77, Step reward: -1, Episode: 0\n",
      "Agent position: [6 0], Target position: [0 2], Total reward: -78, Step reward: -1, Episode: 0\n",
      "Agent position: [6 1], Target position: [0 2], Total reward: -79, Step reward: -1, Episode: 0\n",
      "Agent position: [6 2], Target position: [0 2], Total reward: -80, Step reward: -1, Episode: 0\n",
      "Agent position: [6 3], Target position: [0 2], Total reward: -81, Step reward: -1, Episode: 0\n",
      "Agent position: [5 3], Target position: [0 2], Total reward: -82, Step reward: -1, Episode: 0\n",
      "Agent position: [5 4], Target position: [0 2], Total reward: -83, Step reward: -1, Episode: 0\n",
      "Agent position: [5 5], Target position: [0 2], Total reward: -84, Step reward: -1, Episode: 0\n",
      "Agent position: [6 5], Target position: [0 2], Total reward: -85, Step reward: -1, Episode: 0\n",
      "Agent position: [5 5], Target position: [0 2], Total reward: -86, Step reward: -1, Episode: 0\n",
      "Agent position: [5 6], Target position: [0 2], Total reward: -87, Step reward: -1, Episode: 0\n",
      "Agent position: [5 5], Target position: [0 2], Total reward: -88, Step reward: -1, Episode: 0\n",
      "Agent position: [6 5], Target position: [0 2], Total reward: -89, Step reward: -1, Episode: 0\n",
      "Agent position: [7 5], Target position: [0 2], Total reward: -90, Step reward: -1, Episode: 0\n",
      "Agent position: [8 5], Target position: [0 2], Total reward: -91, Step reward: -1, Episode: 0\n",
      "Agent position: [9 5], Target position: [0 2], Total reward: -92, Step reward: -1, Episode: 0\n",
      "Agent position: [9 5], Target position: [0 2], Total reward: -102, Step reward: -10, Episode: 0\n",
      "Agent position: [8 5], Target position: [0 2], Total reward: -103, Step reward: -1, Episode: 0\n",
      "Agent position: [8 4], Target position: [0 2], Total reward: -104, Step reward: -1, Episode: 0\n",
      "Agent position: [8 3], Target position: [0 2], Total reward: -105, Step reward: -1, Episode: 0\n",
      "Agent position: [8 2], Target position: [0 2], Total reward: -106, Step reward: -1, Episode: 0\n",
      "Agent position: [8 3], Target position: [0 2], Total reward: -107, Step reward: -1, Episode: 0\n",
      "Agent position: [9 3], Target position: [0 2], Total reward: -108, Step reward: -1, Episode: 0\n",
      "Agent position: [9 2], Target position: [0 2], Total reward: -109, Step reward: -1, Episode: 0\n",
      "Agent position: [9 3], Target position: [0 2], Total reward: -110, Step reward: -1, Episode: 0\n",
      "Agent position: [9 2], Target position: [0 2], Total reward: -111, Step reward: -1, Episode: 0\n",
      "Agent position: [9 2], Target position: [0 2], Total reward: -121, Step reward: -10, Episode: 0\n",
      "Agent position: [8 2], Target position: [0 2], Total reward: -122, Step reward: -1, Episode: 0\n",
      "Agent position: [8 3], Target position: [0 2], Total reward: -123, Step reward: -1, Episode: 0\n",
      "Agent position: [9 3], Target position: [0 2], Total reward: -124, Step reward: -1, Episode: 0\n",
      "Agent position: [9 3], Target position: [0 2], Total reward: -134, Step reward: -10, Episode: 0\n",
      "Agent position: [9 4], Target position: [0 2], Total reward: -135, Step reward: -1, Episode: 0\n",
      "Agent position: [9 4], Target position: [0 2], Total reward: -145, Step reward: -10, Episode: 0\n",
      "Agent position: [9 3], Target position: [0 2], Total reward: -146, Step reward: -1, Episode: 0\n",
      "Agent position: [9 2], Target position: [0 2], Total reward: -147, Step reward: -1, Episode: 0\n",
      "Agent position: [9 3], Target position: [0 2], Total reward: -148, Step reward: -1, Episode: 0\n",
      "Agent position: [8 3], Target position: [0 2], Total reward: -149, Step reward: -1, Episode: 0\n",
      "Agent position: [7 3], Target position: [0 2], Total reward: -150, Step reward: -1, Episode: 0\n",
      "Agent position: [8 3], Target position: [0 2], Total reward: -151, Step reward: -1, Episode: 0\n",
      "Agent position: [9 3], Target position: [0 2], Total reward: -152, Step reward: -1, Episode: 0\n",
      "Agent position: [9 2], Target position: [0 2], Total reward: -153, Step reward: -1, Episode: 0\n",
      "Agent position: [9 1], Target position: [0 2], Total reward: -154, Step reward: -1, Episode: 0\n",
      "Agent position: [9 0], Target position: [0 2], Total reward: -155, Step reward: -1, Episode: 0\n",
      "Agent position: [9 0], Target position: [0 2], Total reward: -165, Step reward: -10, Episode: 0\n",
      "Agent position: [9 1], Target position: [0 2], Total reward: -166, Step reward: -1, Episode: 0\n",
      "Agent position: [9 2], Target position: [0 2], Total reward: -167, Step reward: -1, Episode: 0\n",
      "Agent position: [9 3], Target position: [0 2], Total reward: -168, Step reward: -1, Episode: 0\n",
      "Agent position: [9 2], Target position: [0 2], Total reward: -169, Step reward: -1, Episode: 0\n",
      "Agent position: [9 3], Target position: [0 2], Total reward: -170, Step reward: -1, Episode: 0\n",
      "Agent position: [8 3], Target position: [0 2], Total reward: -171, Step reward: -1, Episode: 0\n",
      "Agent position: [7 3], Target position: [0 2], Total reward: -172, Step reward: -1, Episode: 0\n",
      "Agent position: [7 2], Target position: [0 2], Total reward: -173, Step reward: -1, Episode: 0\n",
      "Agent position: [7 3], Target position: [0 2], Total reward: -174, Step reward: -1, Episode: 0\n",
      "Agent position: [7 2], Target position: [0 2], Total reward: -175, Step reward: -1, Episode: 0\n",
      "Agent position: [7 3], Target position: [0 2], Total reward: -176, Step reward: -1, Episode: 0\n",
      "Agent position: [7 2], Target position: [0 2], Total reward: -177, Step reward: -1, Episode: 0\n",
      "Agent position: [6 2], Target position: [0 2], Total reward: -178, Step reward: -1, Episode: 0\n",
      "Agent position: [6 1], Target position: [0 2], Total reward: -179, Step reward: -1, Episode: 0\n",
      "Agent position: [6 2], Target position: [0 2], Total reward: -180, Step reward: -1, Episode: 0\n",
      "Agent position: [6 1], Target position: [0 2], Total reward: -181, Step reward: -1, Episode: 0\n",
      "Agent position: [6 2], Target position: [0 2], Total reward: -182, Step reward: -1, Episode: 0\n",
      "Agent position: [6 1], Target position: [0 2], Total reward: -183, Step reward: -1, Episode: 0\n",
      "Agent position: [6 0], Target position: [0 2], Total reward: -184, Step reward: -1, Episode: 0\n",
      "Agent position: [5 0], Target position: [0 2], Total reward: -185, Step reward: -1, Episode: 0\n",
      "Agent position: [4 0], Target position: [0 2], Total reward: -186, Step reward: -1, Episode: 0\n",
      "Agent position: [3 0], Target position: [0 2], Total reward: -187, Step reward: -1, Episode: 0\n",
      "Agent position: [3 0], Target position: [0 2], Total reward: -197, Step reward: -10, Episode: 0\n",
      "Agent position: [2 0], Target position: [0 2], Total reward: -197, Step reward: 0, Episode: 0\n",
      "Agent position: [2 0], Target position: [0 2], Total reward: -206, Step reward: -9, Episode: 0\n",
      "Agent position: [3 0], Target position: [0 2], Total reward: -207, Step reward: -1, Episode: 0\n",
      "Agent position: [4 0], Target position: [0 2], Total reward: -208, Step reward: -1, Episode: 0\n",
      "Agent position: [4 1], Target position: [0 2], Total reward: -209, Step reward: -1, Episode: 0\n",
      "Agent position: [3 1], Target position: [0 2], Total reward: -209, Step reward: 0, Episode: 0\n",
      "Agent position: [4 1], Target position: [0 2], Total reward: -210, Step reward: -1, Episode: 0\n",
      "Agent position: [4 0], Target position: [0 2], Total reward: -211, Step reward: -1, Episode: 0\n",
      "Agent position: [3 0], Target position: [0 2], Total reward: -212, Step reward: -1, Episode: 0\n",
      "Agent position: [2 0], Target position: [0 2], Total reward: -212, Step reward: 0, Episode: 0\n",
      "Agent position: [1 0], Target position: [0 2], Total reward: -212, Step reward: 0, Episode: 0\n",
      "Agent position: [1 1], Target position: [0 2], Total reward: -212, Step reward: 0, Episode: 0\n",
      "Agent position: [0 1], Target position: [0 2], Total reward: -211, Step reward: 1, Episode: 0\n",
      "Agent position: [0 0], Target position: [0 2], Total reward: -211, Step reward: 0, Episode: 0\n",
      "Agent position: [0 1], Target position: [0 2], Total reward: -210, Step reward: 1, Episode: 0\n",
      "Agent position: [0 0], Target position: [0 2], Total reward: -210, Step reward: 0, Episode: 0\n",
      "Agent position: [1 0], Target position: [0 2], Total reward: -210, Step reward: 0, Episode: 0\n",
      "Agent position: [0 0], Target position: [0 2], Total reward: -210, Step reward: 0, Episode: 0\n",
      "Agent position: [0 0], Target position: [0 2], Total reward: -219, Step reward: -9, Episode: 0\n",
      "Agent position: [0 1], Target position: [0 2], Total reward: -218, Step reward: 1, Episode: 0\n",
      "Agent position: [0 2], Target position: [0 2], Total reward: -217, Step reward: 1, Episode: 0\n",
      "Agent position: [4 3], Target position: [3 4], Total reward: 0, Step reward: 0, Episode: 1\n",
      "Agent position: [4 2], Target position: [3 4], Total reward: 0, Step reward: 0, Episode: 1\n",
      "Agent position: [5 2], Target position: [3 4], Total reward: 0, Step reward: 0, Episode: 1\n",
      "Agent position: [5 1], Target position: [3 4], Total reward: -1, Step reward: -1, Episode: 1\n",
      "Agent position: [5 2], Target position: [3 4], Total reward: -1, Step reward: 0, Episode: 1\n",
      "Agent position: [6 2], Target position: [3 4], Total reward: -2, Step reward: -1, Episode: 1\n",
      "Agent position: [7 2], Target position: [3 4], Total reward: -3, Step reward: -1, Episode: 1\n",
      "Agent position: [6 2], Target position: [3 4], Total reward: -4, Step reward: -1, Episode: 1\n",
      "Agent position: [6 3], Target position: [3 4], Total reward: -4, Step reward: 0, Episode: 1\n",
      "Agent position: [7 3], Target position: [3 4], Total reward: -5, Step reward: -1, Episode: 1\n",
      "Agent position: [6 3], Target position: [3 4], Total reward: -5, Step reward: 0, Episode: 1\n",
      "Agent position: [5 3], Target position: [3 4], Total reward: -5, Step reward: 0, Episode: 1\n",
      "Agent position: [5 2], Target position: [3 4], Total reward: -5, Step reward: 0, Episode: 1\n",
      "Agent position: [6 2], Target position: [3 4], Total reward: -6, Step reward: -1, Episode: 1\n",
      "Agent position: [6 1], Target position: [3 4], Total reward: -7, Step reward: -1, Episode: 1\n",
      "Agent position: [7 1], Target position: [3 4], Total reward: -8, Step reward: -1, Episode: 1\n",
      "Agent position: [8 1], Target position: [3 4], Total reward: -9, Step reward: -1, Episode: 1\n",
      "Agent position: [9 1], Target position: [3 4], Total reward: -10, Step reward: -1, Episode: 1\n",
      "Agent position: [8 1], Target position: [3 4], Total reward: -11, Step reward: -1, Episode: 1\n",
      "Agent position: [8 0], Target position: [3 4], Total reward: -12, Step reward: -1, Episode: 1\n",
      "Agent position: [8 0], Target position: [3 4], Total reward: -22, Step reward: -10, Episode: 1\n",
      "Agent position: [8 1], Target position: [3 4], Total reward: -23, Step reward: -1, Episode: 1\n",
      "Agent position: [8 2], Target position: [3 4], Total reward: -24, Step reward: -1, Episode: 1\n",
      "Agent position: [9 2], Target position: [3 4], Total reward: -25, Step reward: -1, Episode: 1\n",
      "Agent position: [8 2], Target position: [3 4], Total reward: -26, Step reward: -1, Episode: 1\n",
      "Agent position: [8 1], Target position: [3 4], Total reward: -27, Step reward: -1, Episode: 1\n",
      "Agent position: [8 0], Target position: [3 4], Total reward: -28, Step reward: -1, Episode: 1\n",
      "Agent position: [7 0], Target position: [3 4], Total reward: -29, Step reward: -1, Episode: 1\n",
      "Agent position: [7 0], Target position: [3 4], Total reward: -39, Step reward: -10, Episode: 1\n",
      "Agent position: [6 0], Target position: [3 4], Total reward: -40, Step reward: -1, Episode: 1\n",
      "Agent position: [7 0], Target position: [3 4], Total reward: -41, Step reward: -1, Episode: 1\n",
      "Agent position: [7 1], Target position: [3 4], Total reward: -42, Step reward: -1, Episode: 1\n",
      "Agent position: [8 1], Target position: [3 4], Total reward: -43, Step reward: -1, Episode: 1\n",
      "Agent position: [9 1], Target position: [3 4], Total reward: -44, Step reward: -1, Episode: 1\n",
      "Agent position: [9 1], Target position: [3 4], Total reward: -54, Step reward: -10, Episode: 1\n",
      "Agent position: [9 2], Target position: [3 4], Total reward: -55, Step reward: -1, Episode: 1\n",
      "Agent position: [9 1], Target position: [3 4], Total reward: -56, Step reward: -1, Episode: 1\n",
      "Agent position: [9 0], Target position: [3 4], Total reward: -57, Step reward: -1, Episode: 1\n",
      "Agent position: [9 1], Target position: [3 4], Total reward: -58, Step reward: -1, Episode: 1\n",
      "Agent position: [8 1], Target position: [3 4], Total reward: -59, Step reward: -1, Episode: 1\n",
      "Agent position: [7 1], Target position: [3 4], Total reward: -60, Step reward: -1, Episode: 1\n",
      "Agent position: [8 1], Target position: [3 4], Total reward: -61, Step reward: -1, Episode: 1\n",
      "Agent position: [7 1], Target position: [3 4], Total reward: -62, Step reward: -1, Episode: 1\n",
      "Agent position: [7 0], Target position: [3 4], Total reward: -63, Step reward: -1, Episode: 1\n",
      "Agent position: [8 0], Target position: [3 4], Total reward: -64, Step reward: -1, Episode: 1\n",
      "Agent position: [7 0], Target position: [3 4], Total reward: -65, Step reward: -1, Episode: 1\n",
      "Agent position: [8 0], Target position: [3 4], Total reward: -66, Step reward: -1, Episode: 1\n",
      "Agent position: [7 0], Target position: [3 4], Total reward: -67, Step reward: -1, Episode: 1\n",
      "Agent position: [7 0], Target position: [3 4], Total reward: -77, Step reward: -10, Episode: 1\n",
      "Agent position: [7 0], Target position: [3 4], Total reward: -87, Step reward: -10, Episode: 1\n",
      "Agent position: [8 0], Target position: [3 4], Total reward: -88, Step reward: -1, Episode: 1\n",
      "Agent position: [8 1], Target position: [3 4], Total reward: -89, Step reward: -1, Episode: 1\n",
      "Agent position: [8 2], Target position: [3 4], Total reward: -90, Step reward: -1, Episode: 1\n",
      "Agent position: [8 1], Target position: [3 4], Total reward: -91, Step reward: -1, Episode: 1\n",
      "Agent position: [7 1], Target position: [3 4], Total reward: -92, Step reward: -1, Episode: 1\n",
      "Agent position: [6 1], Target position: [3 4], Total reward: -93, Step reward: -1, Episode: 1\n",
      "Agent position: [6 2], Target position: [3 4], Total reward: -94, Step reward: -1, Episode: 1\n",
      "Agent position: [6 3], Target position: [3 4], Total reward: -94, Step reward: 0, Episode: 1\n",
      "Agent position: [6 4], Target position: [3 4], Total reward: -94, Step reward: 0, Episode: 1\n",
      "Agent position: [5 4], Target position: [3 4], Total reward: -94, Step reward: 0, Episode: 1\n",
      "Agent position: [5 5], Target position: [3 4], Total reward: -94, Step reward: 0, Episode: 1\n",
      "Agent position: [6 5], Target position: [3 4], Total reward: -94, Step reward: 0, Episode: 1\n",
      "Agent position: [5 5], Target position: [3 4], Total reward: -94, Step reward: 0, Episode: 1\n",
      "Agent position: [5 6], Target position: [3 4], Total reward: -94, Step reward: 0, Episode: 1\n",
      "Agent position: [6 6], Target position: [3 4], Total reward: -95, Step reward: -1, Episode: 1\n",
      "Agent position: [5 6], Target position: [3 4], Total reward: -95, Step reward: 0, Episode: 1\n",
      "Agent position: [4 6], Target position: [3 4], Total reward: -95, Step reward: 0, Episode: 1\n",
      "Agent position: [3 6], Target position: [3 4], Total reward: -95, Step reward: 0, Episode: 1\n",
      "Agent position: [3 5], Target position: [3 4], Total reward: -94, Step reward: 1, Episode: 1\n",
      "Agent position: [3 6], Target position: [3 4], Total reward: -94, Step reward: 0, Episode: 1\n",
      "Agent position: [3 7], Target position: [3 4], Total reward: -94, Step reward: 0, Episode: 1\n",
      "Agent position: [3 6], Target position: [3 4], Total reward: -94, Step reward: 0, Episode: 1\n",
      "Agent position: [2 6], Target position: [3 4], Total reward: -94, Step reward: 0, Episode: 1\n",
      "Agent position: [2 5], Target position: [3 4], Total reward: -94, Step reward: 0, Episode: 1\n",
      "Agent position: [2 4], Target position: [3 4], Total reward: -93, Step reward: 1, Episode: 1\n",
      "Agent position: [1 4], Target position: [3 4], Total reward: -93, Step reward: 0, Episode: 1\n",
      "Agent position: [1 3], Target position: [3 4], Total reward: -93, Step reward: 0, Episode: 1\n",
      "Agent position: [1 4], Target position: [3 4], Total reward: -93, Step reward: 0, Episode: 1\n",
      "Agent position: [2 4], Target position: [3 4], Total reward: -92, Step reward: 1, Episode: 1\n",
      "Agent position: [1 4], Target position: [3 4], Total reward: -92, Step reward: 0, Episode: 1\n",
      "Agent position: [0 4], Target position: [3 4], Total reward: -92, Step reward: 0, Episode: 1\n",
      "Agent position: [1 4], Target position: [3 4], Total reward: -92, Step reward: 0, Episode: 1\n",
      "Agent position: [1 5], Target position: [3 4], Total reward: -92, Step reward: 0, Episode: 1\n",
      "Agent position: [0 5], Target position: [3 4], Total reward: -92, Step reward: 0, Episode: 1\n",
      "Agent position: [0 6], Target position: [3 4], Total reward: -93, Step reward: -1, Episode: 1\n",
      "Agent position: [1 6], Target position: [3 4], Total reward: -93, Step reward: 0, Episode: 1\n",
      "Agent position: [1 7], Target position: [3 4], Total reward: -94, Step reward: -1, Episode: 1\n",
      "Agent position: [0 7], Target position: [3 4], Total reward: -95, Step reward: -1, Episode: 1\n",
      "Agent position: [0 7], Target position: [3 4], Total reward: -105, Step reward: -10, Episode: 1\n",
      "Agent position: [0 7], Target position: [3 4], Total reward: -115, Step reward: -10, Episode: 1\n",
      "Agent position: [0 8], Target position: [3 4], Total reward: -116, Step reward: -1, Episode: 1\n",
      "Agent position: [0 7], Target position: [3 4], Total reward: -117, Step reward: -1, Episode: 1\n",
      "Agent position: [0 6], Target position: [3 4], Total reward: -118, Step reward: -1, Episode: 1\n",
      "Agent position: [0 7], Target position: [3 4], Total reward: -119, Step reward: -1, Episode: 1\n",
      "Agent position: [0 6], Target position: [3 4], Total reward: -120, Step reward: -1, Episode: 1\n",
      "Agent position: [0 5], Target position: [3 4], Total reward: -120, Step reward: 0, Episode: 1\n",
      "Agent position: [0 5], Target position: [3 4], Total reward: -129, Step reward: -9, Episode: 1\n",
      "Agent position: [0 4], Target position: [3 4], Total reward: -129, Step reward: 0, Episode: 1\n",
      "Agent position: [0 5], Target position: [3 4], Total reward: -129, Step reward: 0, Episode: 1\n",
      "Agent position: [0 6], Target position: [3 4], Total reward: -130, Step reward: -1, Episode: 1\n",
      "Agent position: [1 6], Target position: [3 4], Total reward: -130, Step reward: 0, Episode: 1\n",
      "Agent position: [1 7], Target position: [3 4], Total reward: -131, Step reward: -1, Episode: 1\n",
      "Agent position: [1 8], Target position: [3 4], Total reward: -132, Step reward: -1, Episode: 1\n",
      "Agent position: [2 8], Target position: [3 4], Total reward: -133, Step reward: -1, Episode: 1\n",
      "Agent position: [3 8], Target position: [3 4], Total reward: -133, Step reward: 0, Episode: 1\n",
      "Agent position: [4 8], Target position: [3 4], Total reward: -134, Step reward: -1, Episode: 1\n",
      "Agent position: [3 8], Target position: [3 4], Total reward: -134, Step reward: 0, Episode: 1\n",
      "Agent position: [4 8], Target position: [3 4], Total reward: -135, Step reward: -1, Episode: 1\n",
      "Agent position: [3 8], Target position: [3 4], Total reward: -135, Step reward: 0, Episode: 1\n",
      "Agent position: [4 8], Target position: [3 4], Total reward: -136, Step reward: -1, Episode: 1\n",
      "Agent position: [5 8], Target position: [3 4], Total reward: -137, Step reward: -1, Episode: 1\n",
      "Agent position: [5 9], Target position: [3 4], Total reward: -138, Step reward: -1, Episode: 1\n",
      "Agent position: [5 9], Target position: [3 4], Total reward: -148, Step reward: -10, Episode: 1\n",
      "Agent position: [5 8], Target position: [3 4], Total reward: -149, Step reward: -1, Episode: 1\n",
      "Agent position: [6 8], Target position: [3 4], Total reward: -150, Step reward: -1, Episode: 1\n",
      "Agent position: [6 9], Target position: [3 4], Total reward: -151, Step reward: -1, Episode: 1\n",
      "Agent position: [5 9], Target position: [3 4], Total reward: -152, Step reward: -1, Episode: 1\n",
      "Agent position: [5 9], Target position: [3 4], Total reward: -162, Step reward: -10, Episode: 1\n",
      "Agent position: [4 9], Target position: [3 4], Total reward: -163, Step reward: -1, Episode: 1\n",
      "Agent position: [5 9], Target position: [3 4], Total reward: -164, Step reward: -1, Episode: 1\n",
      "Agent position: [6 9], Target position: [3 4], Total reward: -165, Step reward: -1, Episode: 1\n",
      "Agent position: [6 9], Target position: [3 4], Total reward: -175, Step reward: -10, Episode: 1\n",
      "Agent position: [5 9], Target position: [3 4], Total reward: -176, Step reward: -1, Episode: 1\n",
      "Agent position: [5 8], Target position: [3 4], Total reward: -177, Step reward: -1, Episode: 1\n",
      "Agent position: [5 7], Target position: [3 4], Total reward: -178, Step reward: -1, Episode: 1\n",
      "Agent position: [5 6], Target position: [3 4], Total reward: -178, Step reward: 0, Episode: 1\n",
      "Agent position: [4 6], Target position: [3 4], Total reward: -178, Step reward: 0, Episode: 1\n",
      "Agent position: [4 7], Target position: [3 4], Total reward: -178, Step reward: 0, Episode: 1\n",
      "Agent position: [4 8], Target position: [3 4], Total reward: -179, Step reward: -1, Episode: 1\n",
      "Agent position: [4 7], Target position: [3 4], Total reward: -179, Step reward: 0, Episode: 1\n",
      "Agent position: [4 6], Target position: [3 4], Total reward: -179, Step reward: 0, Episode: 1\n",
      "Agent position: [3 6], Target position: [3 4], Total reward: -179, Step reward: 0, Episode: 1\n",
      "Agent position: [3 5], Target position: [3 4], Total reward: -178, Step reward: 1, Episode: 1\n",
      "Agent position: [4 5], Target position: [3 4], Total reward: -178, Step reward: 0, Episode: 1\n",
      "Agent position: [5 5], Target position: [3 4], Total reward: -178, Step reward: 0, Episode: 1\n",
      "Agent position: [6 5], Target position: [3 4], Total reward: -178, Step reward: 0, Episode: 1\n",
      "Agent position: [6 4], Target position: [3 4], Total reward: -178, Step reward: 0, Episode: 1\n",
      "Agent position: [6 5], Target position: [3 4], Total reward: -178, Step reward: 0, Episode: 1\n",
      "Agent position: [5 5], Target position: [3 4], Total reward: -178, Step reward: 0, Episode: 1\n",
      "Agent position: [5 4], Target position: [3 4], Total reward: -178, Step reward: 0, Episode: 1\n",
      "Agent position: [5 5], Target position: [3 4], Total reward: -178, Step reward: 0, Episode: 1\n",
      "Agent position: [4 5], Target position: [3 4], Total reward: -178, Step reward: 0, Episode: 1\n",
      "Agent position: [4 4], Target position: [3 4], Total reward: -177, Step reward: 1, Episode: 1\n",
      "Agent position: [5 4], Target position: [3 4], Total reward: -177, Step reward: 0, Episode: 1\n",
      "Agent position: [5 5], Target position: [3 4], Total reward: -177, Step reward: 0, Episode: 1\n",
      "Agent position: [5 4], Target position: [3 4], Total reward: -177, Step reward: 0, Episode: 1\n",
      "Agent position: [4 4], Target position: [3 4], Total reward: -176, Step reward: 1, Episode: 1\n",
      "Agent position: [4 5], Target position: [3 4], Total reward: -176, Step reward: 0, Episode: 1\n",
      "Agent position: [4 6], Target position: [3 4], Total reward: -176, Step reward: 0, Episode: 1\n",
      "Agent position: [3 6], Target position: [3 4], Total reward: -176, Step reward: 0, Episode: 1\n",
      "Agent position: [2 6], Target position: [3 4], Total reward: -176, Step reward: 0, Episode: 1\n",
      "Agent position: [3 6], Target position: [3 4], Total reward: -176, Step reward: 0, Episode: 1\n",
      "Agent position: [3 5], Target position: [3 4], Total reward: -175, Step reward: 1, Episode: 1\n",
      "Agent position: [3 4], Target position: [3 4], Total reward: -174, Step reward: 1, Episode: 1\n",
      "Agent position: [6 0], Target position: [4 1], Total reward: -9, Step reward: -9, Episode: 2\n",
      "Agent position: [6 0], Target position: [4 1], Total reward: -18, Step reward: -9, Episode: 2\n",
      "Agent position: [6 0], Target position: [4 1], Total reward: -27, Step reward: -9, Episode: 2\n",
      "Agent position: [7 0], Target position: [4 1], Total reward: -27, Step reward: 0, Episode: 2\n",
      "Agent position: [6 0], Target position: [4 1], Total reward: -27, Step reward: 0, Episode: 2\n",
      "Agent position: [7 0], Target position: [4 1], Total reward: -27, Step reward: 0, Episode: 2\n",
      "Agent position: [8 0], Target position: [4 1], Total reward: -28, Step reward: -1, Episode: 2\n",
      "Agent position: [8 1], Target position: [4 1], Total reward: -28, Step reward: 0, Episode: 2\n",
      "Agent position: [7 1], Target position: [4 1], Total reward: -28, Step reward: 0, Episode: 2\n",
      "Agent position: [7 2], Target position: [4 1], Total reward: -28, Step reward: 0, Episode: 2\n",
      "Agent position: [8 2], Target position: [4 1], Total reward: -29, Step reward: -1, Episode: 2\n",
      "Agent position: [8 1], Target position: [4 1], Total reward: -29, Step reward: 0, Episode: 2\n",
      "Agent position: [9 1], Target position: [4 1], Total reward: -30, Step reward: -1, Episode: 2\n",
      "Agent position: [8 1], Target position: [4 1], Total reward: -30, Step reward: 0, Episode: 2\n",
      "Agent position: [8 0], Target position: [4 1], Total reward: -31, Step reward: -1, Episode: 2\n",
      "Agent position: [7 0], Target position: [4 1], Total reward: -31, Step reward: 0, Episode: 2\n",
      "Agent position: [6 0], Target position: [4 1], Total reward: -31, Step reward: 0, Episode: 2\n",
      "Agent position: [6 1], Target position: [4 1], Total reward: -31, Step reward: 0, Episode: 2\n",
      "Agent position: [5 1], Target position: [4 1], Total reward: -30, Step reward: 1, Episode: 2\n",
      "Agent position: [5 0], Target position: [4 1], Total reward: -30, Step reward: 0, Episode: 2\n",
      "Agent position: [5 0], Target position: [4 1], Total reward: -39, Step reward: -9, Episode: 2\n",
      "Agent position: [6 0], Target position: [4 1], Total reward: -39, Step reward: 0, Episode: 2\n",
      "Agent position: [5 0], Target position: [4 1], Total reward: -39, Step reward: 0, Episode: 2\n",
      "Agent position: [4 0], Target position: [4 1], Total reward: -38, Step reward: 1, Episode: 2\n",
      "Agent position: [3 0], Target position: [4 1], Total reward: -38, Step reward: 0, Episode: 2\n",
      "Agent position: [3 1], Target position: [4 1], Total reward: -37, Step reward: 1, Episode: 2\n",
      "Agent position: [4 1], Target position: [4 1], Total reward: -36, Step reward: 1, Episode: 2\n",
      "Agent position: [6 8], Target position: [1 7], Total reward: -1, Step reward: -1, Episode: 3\n",
      "Agent position: [6 9], Target position: [1 7], Total reward: -2, Step reward: -1, Episode: 3\n",
      "Agent position: [5 9], Target position: [1 7], Total reward: -3, Step reward: -1, Episode: 3\n",
      "Agent position: [6 9], Target position: [1 7], Total reward: -4, Step reward: -1, Episode: 3\n",
      "Agent position: [6 9], Target position: [1 7], Total reward: -14, Step reward: -10, Episode: 3\n",
      "Agent position: [7 9], Target position: [1 7], Total reward: -15, Step reward: -1, Episode: 3\n",
      "Agent position: [7 8], Target position: [1 7], Total reward: -16, Step reward: -1, Episode: 3\n",
      "Agent position: [7 9], Target position: [1 7], Total reward: -17, Step reward: -1, Episode: 3\n",
      "Agent position: [8 9], Target position: [1 7], Total reward: -18, Step reward: -1, Episode: 3\n",
      "Agent position: [7 9], Target position: [1 7], Total reward: -19, Step reward: -1, Episode: 3\n",
      "Agent position: [7 8], Target position: [1 7], Total reward: -20, Step reward: -1, Episode: 3\n",
      "Agent position: [7 9], Target position: [1 7], Total reward: -21, Step reward: -1, Episode: 3\n",
      "Agent position: [7 9], Target position: [1 7], Total reward: -31, Step reward: -10, Episode: 3\n",
      "Agent position: [7 9], Target position: [1 7], Total reward: -41, Step reward: -10, Episode: 3\n",
      "Agent position: [8 9], Target position: [1 7], Total reward: -42, Step reward: -1, Episode: 3\n",
      "Agent position: [7 9], Target position: [1 7], Total reward: -43, Step reward: -1, Episode: 3\n",
      "Agent position: [6 9], Target position: [1 7], Total reward: -44, Step reward: -1, Episode: 3\n",
      "Agent position: [6 9], Target position: [1 7], Total reward: -54, Step reward: -10, Episode: 3\n",
      "Agent position: [5 9], Target position: [1 7], Total reward: -55, Step reward: -1, Episode: 3\n",
      "Agent position: [5 9], Target position: [1 7], Total reward: -65, Step reward: -10, Episode: 3\n",
      "Agent position: [5 9], Target position: [1 7], Total reward: -75, Step reward: -10, Episode: 3\n",
      "Agent position: [5 8], Target position: [1 7], Total reward: -76, Step reward: -1, Episode: 3\n",
      "Agent position: [6 8], Target position: [1 7], Total reward: -77, Step reward: -1, Episode: 3\n",
      "Agent position: [7 8], Target position: [1 7], Total reward: -78, Step reward: -1, Episode: 3\n",
      "Agent position: [8 8], Target position: [1 7], Total reward: -79, Step reward: -1, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -80, Step reward: -1, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -81, Step reward: -1, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -82, Step reward: -1, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -92, Step reward: -10, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -93, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -94, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -104, Step reward: -10, Episode: 3\n",
      "Agent position: [8 6], Target position: [1 7], Total reward: -105, Step reward: -1, Episode: 3\n",
      "Agent position: [7 6], Target position: [1 7], Total reward: -106, Step reward: -1, Episode: 3\n",
      "Agent position: [6 6], Target position: [1 7], Total reward: -107, Step reward: -1, Episode: 3\n",
      "Agent position: [7 6], Target position: [1 7], Total reward: -108, Step reward: -1, Episode: 3\n",
      "Agent position: [7 7], Target position: [1 7], Total reward: -109, Step reward: -1, Episode: 3\n",
      "Agent position: [7 8], Target position: [1 7], Total reward: -110, Step reward: -1, Episode: 3\n",
      "Agent position: [6 8], Target position: [1 7], Total reward: -111, Step reward: -1, Episode: 3\n",
      "Agent position: [7 8], Target position: [1 7], Total reward: -112, Step reward: -1, Episode: 3\n",
      "Agent position: [6 8], Target position: [1 7], Total reward: -113, Step reward: -1, Episode: 3\n",
      "Agent position: [5 8], Target position: [1 7], Total reward: -114, Step reward: -1, Episode: 3\n",
      "Agent position: [5 7], Target position: [1 7], Total reward: -114, Step reward: 0, Episode: 3\n",
      "Agent position: [6 7], Target position: [1 7], Total reward: -115, Step reward: -1, Episode: 3\n",
      "Agent position: [6 8], Target position: [1 7], Total reward: -116, Step reward: -1, Episode: 3\n",
      "Agent position: [7 8], Target position: [1 7], Total reward: -117, Step reward: -1, Episode: 3\n",
      "Agent position: [7 7], Target position: [1 7], Total reward: -118, Step reward: -1, Episode: 3\n",
      "Agent position: [7 8], Target position: [1 7], Total reward: -119, Step reward: -1, Episode: 3\n",
      "Agent position: [8 8], Target position: [1 7], Total reward: -120, Step reward: -1, Episode: 3\n",
      "Agent position: [8 9], Target position: [1 7], Total reward: -121, Step reward: -1, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -122, Step reward: -1, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -132, Step reward: -10, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -133, Step reward: -1, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -143, Step reward: -10, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -153, Step reward: -10, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -163, Step reward: -10, Episode: 3\n",
      "Agent position: [8 8], Target position: [1 7], Total reward: -164, Step reward: -1, Episode: 3\n",
      "Agent position: [8 9], Target position: [1 7], Total reward: -165, Step reward: -1, Episode: 3\n",
      "Agent position: [8 9], Target position: [1 7], Total reward: -175, Step reward: -10, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -176, Step reward: -1, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -177, Step reward: -1, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -178, Step reward: -1, Episode: 3\n",
      "Agent position: [8 9], Target position: [1 7], Total reward: -179, Step reward: -1, Episode: 3\n",
      "Agent position: [8 8], Target position: [1 7], Total reward: -180, Step reward: -1, Episode: 3\n",
      "Agent position: [7 8], Target position: [1 7], Total reward: -181, Step reward: -1, Episode: 3\n",
      "Agent position: [7 7], Target position: [1 7], Total reward: -182, Step reward: -1, Episode: 3\n",
      "Agent position: [8 7], Target position: [1 7], Total reward: -183, Step reward: -1, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -184, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -185, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -195, Step reward: -10, Episode: 3\n",
      "Agent position: [8 6], Target position: [1 7], Total reward: -196, Step reward: -1, Episode: 3\n",
      "Agent position: [8 5], Target position: [1 7], Total reward: -197, Step reward: -1, Episode: 3\n",
      "Agent position: [7 5], Target position: [1 7], Total reward: -198, Step reward: -1, Episode: 3\n",
      "Agent position: [8 5], Target position: [1 7], Total reward: -199, Step reward: -1, Episode: 3\n",
      "Agent position: [8 4], Target position: [1 7], Total reward: -200, Step reward: -1, Episode: 3\n",
      "Agent position: [8 3], Target position: [1 7], Total reward: -201, Step reward: -1, Episode: 3\n",
      "Agent position: [9 3], Target position: [1 7], Total reward: -202, Step reward: -1, Episode: 3\n",
      "Agent position: [9 4], Target position: [1 7], Total reward: -203, Step reward: -1, Episode: 3\n",
      "Agent position: [9 3], Target position: [1 7], Total reward: -204, Step reward: -1, Episode: 3\n",
      "Agent position: [9 2], Target position: [1 7], Total reward: -205, Step reward: -1, Episode: 3\n",
      "Agent position: [8 2], Target position: [1 7], Total reward: -206, Step reward: -1, Episode: 3\n",
      "Agent position: [8 3], Target position: [1 7], Total reward: -207, Step reward: -1, Episode: 3\n",
      "Agent position: [9 3], Target position: [1 7], Total reward: -208, Step reward: -1, Episode: 3\n",
      "Agent position: [9 2], Target position: [1 7], Total reward: -209, Step reward: -1, Episode: 3\n",
      "Agent position: [8 2], Target position: [1 7], Total reward: -210, Step reward: -1, Episode: 3\n",
      "Agent position: [8 3], Target position: [1 7], Total reward: -211, Step reward: -1, Episode: 3\n",
      "Agent position: [8 4], Target position: [1 7], Total reward: -212, Step reward: -1, Episode: 3\n",
      "Agent position: [8 5], Target position: [1 7], Total reward: -213, Step reward: -1, Episode: 3\n",
      "Agent position: [8 6], Target position: [1 7], Total reward: -214, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -215, Step reward: -1, Episode: 3\n",
      "Agent position: [9 5], Target position: [1 7], Total reward: -216, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -217, Step reward: -1, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -218, Step reward: -1, Episode: 3\n",
      "Agent position: [8 7], Target position: [1 7], Total reward: -219, Step reward: -1, Episode: 3\n",
      "Agent position: [8 6], Target position: [1 7], Total reward: -220, Step reward: -1, Episode: 3\n",
      "Agent position: [7 6], Target position: [1 7], Total reward: -221, Step reward: -1, Episode: 3\n",
      "Agent position: [6 6], Target position: [1 7], Total reward: -222, Step reward: -1, Episode: 3\n",
      "Agent position: [6 5], Target position: [1 7], Total reward: -223, Step reward: -1, Episode: 3\n",
      "Agent position: [6 4], Target position: [1 7], Total reward: -224, Step reward: -1, Episode: 3\n",
      "Agent position: [5 4], Target position: [1 7], Total reward: -225, Step reward: -1, Episode: 3\n",
      "Agent position: [5 5], Target position: [1 7], Total reward: -226, Step reward: -1, Episode: 3\n",
      "Agent position: [5 4], Target position: [1 7], Total reward: -227, Step reward: -1, Episode: 3\n",
      "Agent position: [5 5], Target position: [1 7], Total reward: -228, Step reward: -1, Episode: 3\n",
      "Agent position: [5 6], Target position: [1 7], Total reward: -229, Step reward: -1, Episode: 3\n",
      "Agent position: [5 5], Target position: [1 7], Total reward: -230, Step reward: -1, Episode: 3\n",
      "Agent position: [5 6], Target position: [1 7], Total reward: -231, Step reward: -1, Episode: 3\n",
      "Agent position: [5 7], Target position: [1 7], Total reward: -231, Step reward: 0, Episode: 3\n",
      "Agent position: [6 7], Target position: [1 7], Total reward: -232, Step reward: -1, Episode: 3\n",
      "Agent position: [6 8], Target position: [1 7], Total reward: -233, Step reward: -1, Episode: 3\n",
      "Agent position: [6 7], Target position: [1 7], Total reward: -234, Step reward: -1, Episode: 3\n",
      "Agent position: [6 6], Target position: [1 7], Total reward: -235, Step reward: -1, Episode: 3\n",
      "Agent position: [7 6], Target position: [1 7], Total reward: -236, Step reward: -1, Episode: 3\n",
      "Agent position: [8 6], Target position: [1 7], Total reward: -237, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -238, Step reward: -1, Episode: 3\n",
      "Agent position: [8 6], Target position: [1 7], Total reward: -239, Step reward: -1, Episode: 3\n",
      "Agent position: [8 7], Target position: [1 7], Total reward: -240, Step reward: -1, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -241, Step reward: -1, Episode: 3\n",
      "Agent position: [8 7], Target position: [1 7], Total reward: -242, Step reward: -1, Episode: 3\n",
      "Agent position: [7 7], Target position: [1 7], Total reward: -243, Step reward: -1, Episode: 3\n",
      "Agent position: [7 6], Target position: [1 7], Total reward: -244, Step reward: -1, Episode: 3\n",
      "Agent position: [8 6], Target position: [1 7], Total reward: -245, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -246, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -256, Step reward: -10, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -257, Step reward: -1, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -267, Step reward: -10, Episode: 3\n",
      "Agent position: [8 7], Target position: [1 7], Total reward: -268, Step reward: -1, Episode: 3\n",
      "Agent position: [7 7], Target position: [1 7], Total reward: -269, Step reward: -1, Episode: 3\n",
      "Agent position: [6 7], Target position: [1 7], Total reward: -270, Step reward: -1, Episode: 3\n",
      "Agent position: [6 8], Target position: [1 7], Total reward: -271, Step reward: -1, Episode: 3\n",
      "Agent position: [5 8], Target position: [1 7], Total reward: -272, Step reward: -1, Episode: 3\n",
      "Agent position: [6 8], Target position: [1 7], Total reward: -273, Step reward: -1, Episode: 3\n",
      "Agent position: [6 7], Target position: [1 7], Total reward: -274, Step reward: -1, Episode: 3\n",
      "Agent position: [7 7], Target position: [1 7], Total reward: -275, Step reward: -1, Episode: 3\n",
      "Agent position: [8 7], Target position: [1 7], Total reward: -276, Step reward: -1, Episode: 3\n",
      "Agent position: [8 8], Target position: [1 7], Total reward: -277, Step reward: -1, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -278, Step reward: -1, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -279, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -280, Step reward: -1, Episode: 3\n",
      "Agent position: [8 6], Target position: [1 7], Total reward: -281, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -282, Step reward: -1, Episode: 3\n",
      "Agent position: [8 6], Target position: [1 7], Total reward: -283, Step reward: -1, Episode: 3\n",
      "Agent position: [8 5], Target position: [1 7], Total reward: -284, Step reward: -1, Episode: 3\n",
      "Agent position: [8 4], Target position: [1 7], Total reward: -285, Step reward: -1, Episode: 3\n",
      "Agent position: [8 5], Target position: [1 7], Total reward: -286, Step reward: -1, Episode: 3\n",
      "Agent position: [8 4], Target position: [1 7], Total reward: -287, Step reward: -1, Episode: 3\n",
      "Agent position: [7 4], Target position: [1 7], Total reward: -288, Step reward: -1, Episode: 3\n",
      "Agent position: [8 4], Target position: [1 7], Total reward: -289, Step reward: -1, Episode: 3\n",
      "Agent position: [8 3], Target position: [1 7], Total reward: -290, Step reward: -1, Episode: 3\n",
      "Agent position: [9 3], Target position: [1 7], Total reward: -291, Step reward: -1, Episode: 3\n",
      "Agent position: [9 4], Target position: [1 7], Total reward: -292, Step reward: -1, Episode: 3\n",
      "Agent position: [9 3], Target position: [1 7], Total reward: -293, Step reward: -1, Episode: 3\n",
      "Agent position: [9 4], Target position: [1 7], Total reward: -294, Step reward: -1, Episode: 3\n",
      "Agent position: [9 3], Target position: [1 7], Total reward: -295, Step reward: -1, Episode: 3\n",
      "Agent position: [9 2], Target position: [1 7], Total reward: -296, Step reward: -1, Episode: 3\n",
      "Agent position: [9 2], Target position: [1 7], Total reward: -306, Step reward: -10, Episode: 3\n",
      "Agent position: [9 3], Target position: [1 7], Total reward: -307, Step reward: -1, Episode: 3\n",
      "Agent position: [9 3], Target position: [1 7], Total reward: -317, Step reward: -10, Episode: 3\n",
      "Agent position: [9 4], Target position: [1 7], Total reward: -318, Step reward: -1, Episode: 3\n",
      "Agent position: [9 5], Target position: [1 7], Total reward: -319, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -320, Step reward: -1, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -330, Step reward: -10, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -331, Step reward: -1, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -332, Step reward: -1, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -333, Step reward: -1, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -334, Step reward: -1, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -335, Step reward: -1, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -345, Step reward: -10, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -346, Step reward: -1, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -347, Step reward: -1, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -357, Step reward: -10, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -367, Step reward: -10, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -377, Step reward: -10, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -378, Step reward: -1, Episode: 3\n",
      "Agent position: [9 9], Target position: [1 7], Total reward: -379, Step reward: -1, Episode: 3\n",
      "Agent position: [9 8], Target position: [1 7], Total reward: -380, Step reward: -1, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -381, Step reward: -1, Episode: 3\n",
      "Agent position: [8 7], Target position: [1 7], Total reward: -382, Step reward: -1, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -383, Step reward: -1, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -393, Step reward: -10, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -403, Step reward: -10, Episode: 3\n",
      "Agent position: [9 7], Target position: [1 7], Total reward: -413, Step reward: -10, Episode: 3\n",
      "Agent position: [9 6], Target position: [1 7], Total reward: -414, Step reward: -1, Episode: 3\n",
      "Agent position: [9 5], Target position: [1 7], Total reward: -415, Step reward: -1, Episode: 3\n",
      "Agent position: [9 4], Target position: [1 7], Total reward: -416, Step reward: -1, Episode: 3\n",
      "Agent position: [8 4], Target position: [1 7], Total reward: -417, Step reward: -1, Episode: 3\n",
      "Agent position: [9 4], Target position: [1 7], Total reward: -418, Step reward: -1, Episode: 3\n",
      "Agent position: [9 5], Target position: [1 7], Total reward: -419, Step reward: -1, Episode: 3\n",
      "Agent position: [9 4], Target position: [1 7], Total reward: -420, Step reward: -1, Episode: 3\n",
      "Agent position: [9 5], Target position: [1 7], Total reward: -421, Step reward: -1, Episode: 3\n",
      "Agent position: [9 5], Target position: [1 7], Total reward: -431, Step reward: -10, Episode: 3\n",
      "Agent position: [9 4], Target position: [1 7], Total reward: -432, Step reward: -1, Episode: 3\n",
      "Agent position: [9 5], Target position: [1 7], Total reward: -433, Step reward: -1, Episode: 3\n",
      "Agent position: [9 4], Target position: [1 7], Total reward: -434, Step reward: -1, Episode: 3\n",
      "Agent position: [8 4], Target position: [1 7], Total reward: -435, Step reward: -1, Episode: 3\n",
      "Agent position: [8 5], Target position: [1 7], Total reward: -436, Step reward: -1, Episode: 3\n",
      "Agent position: [8 6], Target position: [1 7], Total reward: -437, Step reward: -1, Episode: 3\n",
      "Agent position: [7 6], Target position: [1 7], Total reward: -438, Step reward: -1, Episode: 3\n",
      "Agent position: [7 5], Target position: [1 7], Total reward: -439, Step reward: -1, Episode: 3\n",
      "Agent position: [6 5], Target position: [1 7], Total reward: -440, Step reward: -1, Episode: 3\n",
      "Agent position: [7 5], Target position: [1 7], Total reward: -441, Step reward: -1, Episode: 3\n",
      "Agent position: [8 5], Target position: [1 7], Total reward: -442, Step reward: -1, Episode: 3\n",
      "Agent position: [7 5], Target position: [1 7], Total reward: -443, Step reward: -1, Episode: 3\n",
      "Agent position: [6 5], Target position: [1 7], Total reward: -444, Step reward: -1, Episode: 3\n",
      "Agent position: [6 4], Target position: [1 7], Total reward: -445, Step reward: -1, Episode: 3\n",
      "Agent position: [5 4], Target position: [1 7], Total reward: -446, Step reward: -1, Episode: 3\n",
      "Agent position: [4 4], Target position: [1 7], Total reward: -447, Step reward: -1, Episode: 3\n",
      "Agent position: [5 4], Target position: [1 7], Total reward: -448, Step reward: -1, Episode: 3\n",
      "Agent position: [5 3], Target position: [1 7], Total reward: -449, Step reward: -1, Episode: 3\n",
      "Agent position: [5 2], Target position: [1 7], Total reward: -450, Step reward: -1, Episode: 3\n",
      "Agent position: [5 3], Target position: [1 7], Total reward: -451, Step reward: -1, Episode: 3\n",
      "Agent position: [5 4], Target position: [1 7], Total reward: -452, Step reward: -1, Episode: 3\n",
      "Agent position: [4 4], Target position: [1 7], Total reward: -453, Step reward: -1, Episode: 3\n",
      "Agent position: [3 4], Target position: [1 7], Total reward: -454, Step reward: -1, Episode: 3\n",
      "Agent position: [3 5], Target position: [1 7], Total reward: -454, Step reward: 0, Episode: 3\n",
      "Agent position: [3 4], Target position: [1 7], Total reward: -455, Step reward: -1, Episode: 3\n",
      "Agent position: [4 4], Target position: [1 7], Total reward: -456, Step reward: -1, Episode: 3\n",
      "Agent position: [5 4], Target position: [1 7], Total reward: -457, Step reward: -1, Episode: 3\n",
      "Agent position: [5 5], Target position: [1 7], Total reward: -458, Step reward: -1, Episode: 3\n",
      "Agent position: [6 5], Target position: [1 7], Total reward: -459, Step reward: -1, Episode: 3\n",
      "Agent position: [6 4], Target position: [1 7], Total reward: -460, Step reward: -1, Episode: 3\n",
      "Agent position: [6 5], Target position: [1 7], Total reward: -461, Step reward: -1, Episode: 3\n",
      "Agent position: [5 5], Target position: [1 7], Total reward: -462, Step reward: -1, Episode: 3\n",
      "Agent position: [4 5], Target position: [1 7], Total reward: -463, Step reward: -1, Episode: 3\n",
      "Agent position: [5 5], Target position: [1 7], Total reward: -464, Step reward: -1, Episode: 3\n",
      "Agent position: [5 6], Target position: [1 7], Total reward: -465, Step reward: -1, Episode: 3\n",
      "Agent position: [5 5], Target position: [1 7], Total reward: -466, Step reward: -1, Episode: 3\n",
      "Agent position: [5 4], Target position: [1 7], Total reward: -467, Step reward: -1, Episode: 3\n",
      "Agent position: [6 4], Target position: [1 7], Total reward: -468, Step reward: -1, Episode: 3\n",
      "Agent position: [5 4], Target position: [1 7], Total reward: -469, Step reward: -1, Episode: 3\n",
      "Agent position: [6 4], Target position: [1 7], Total reward: -470, Step reward: -1, Episode: 3\n",
      "Agent position: [6 3], Target position: [1 7], Total reward: -471, Step reward: -1, Episode: 3\n",
      "Agent position: [6 4], Target position: [1 7], Total reward: -472, Step reward: -1, Episode: 3\n",
      "Agent position: [6 3], Target position: [1 7], Total reward: -473, Step reward: -1, Episode: 3\n",
      "Agent position: [5 3], Target position: [1 7], Total reward: -474, Step reward: -1, Episode: 3\n",
      "Agent position: [6 3], Target position: [1 7], Total reward: -475, Step reward: -1, Episode: 3\n",
      "Agent position: [6 2], Target position: [1 7], Total reward: -476, Step reward: -1, Episode: 3\n",
      "Agent position: [6 1], Target position: [1 7], Total reward: -477, Step reward: -1, Episode: 3\n",
      "Agent position: [5 1], Target position: [1 7], Total reward: -478, Step reward: -1, Episode: 3\n",
      "Agent position: [5 0], Target position: [1 7], Total reward: -479, Step reward: -1, Episode: 3\n",
      "Agent position: [5 1], Target position: [1 7], Total reward: -480, Step reward: -1, Episode: 3\n",
      "Agent position: [5 0], Target position: [1 7], Total reward: -481, Step reward: -1, Episode: 3\n",
      "Agent position: [4 0], Target position: [1 7], Total reward: -482, Step reward: -1, Episode: 3\n",
      "Agent position: [5 0], Target position: [1 7], Total reward: -483, Step reward: -1, Episode: 3\n",
      "Agent position: [4 0], Target position: [1 7], Total reward: -484, Step reward: -1, Episode: 3\n",
      "Agent position: [4 0], Target position: [1 7], Total reward: -494, Step reward: -10, Episode: 3\n",
      "Agent position: [3 0], Target position: [1 7], Total reward: -495, Step reward: -1, Episode: 3\n",
      "Agent position: [3 1], Target position: [1 7], Total reward: -496, Step reward: -1, Episode: 3\n",
      "Agent position: [4 1], Target position: [1 7], Total reward: -497, Step reward: -1, Episode: 3\n",
      "Agent position: [5 1], Target position: [1 7], Total reward: -498, Step reward: -1, Episode: 3\n",
      "Agent position: [5 2], Target position: [1 7], Total reward: -499, Step reward: -1, Episode: 3\n",
      "Agent position: [5 1], Target position: [1 7], Total reward: -500, Step reward: -1, Episode: 3\n",
      "Agent position: [5 2], Target position: [1 7], Total reward: -501, Step reward: -1, Episode: 3\n",
      "Agent position: [4 2], Target position: [1 7], Total reward: -502, Step reward: -1, Episode: 3\n",
      "Agent position: [5 2], Target position: [1 7], Total reward: -503, Step reward: -1, Episode: 3\n",
      "Agent position: [4 2], Target position: [1 7], Total reward: -504, Step reward: -1, Episode: 3\n",
      "Agent position: [3 2], Target position: [1 7], Total reward: -505, Step reward: -1, Episode: 3\n",
      "Agent position: [3 3], Target position: [1 7], Total reward: -506, Step reward: -1, Episode: 3\n",
      "Agent position: [3 2], Target position: [1 7], Total reward: -507, Step reward: -1, Episode: 3\n",
      "Agent position: [2 2], Target position: [1 7], Total reward: -508, Step reward: -1, Episode: 3\n",
      "Agent position: [2 3], Target position: [1 7], Total reward: -509, Step reward: -1, Episode: 3\n",
      "Agent position: [2 4], Target position: [1 7], Total reward: -509, Step reward: 0, Episode: 3\n",
      "Agent position: [2 5], Target position: [1 7], Total reward: -509, Step reward: 0, Episode: 3\n",
      "Agent position: [2 6], Target position: [1 7], Total reward: -509, Step reward: 0, Episode: 3\n",
      "Agent position: [3 6], Target position: [1 7], Total reward: -509, Step reward: 0, Episode: 3\n",
      "Agent position: [4 6], Target position: [1 7], Total reward: -509, Step reward: 0, Episode: 3\n",
      "Agent position: [5 6], Target position: [1 7], Total reward: -510, Step reward: -1, Episode: 3\n",
      "Agent position: [6 6], Target position: [1 7], Total reward: -511, Step reward: -1, Episode: 3\n",
      "Agent position: [5 6], Target position: [1 7], Total reward: -512, Step reward: -1, Episode: 3\n",
      "Agent position: [4 6], Target position: [1 7], Total reward: -512, Step reward: 0, Episode: 3\n",
      "Agent position: [3 6], Target position: [1 7], Total reward: -512, Step reward: 0, Episode: 3\n",
      "Agent position: [4 6], Target position: [1 7], Total reward: -512, Step reward: 0, Episode: 3\n",
      "Agent position: [3 6], Target position: [1 7], Total reward: -512, Step reward: 0, Episode: 3\n",
      "Agent position: [3 5], Target position: [1 7], Total reward: -512, Step reward: 0, Episode: 3\n",
      "Agent position: [4 5], Target position: [1 7], Total reward: -513, Step reward: -1, Episode: 3\n",
      "Agent position: [3 5], Target position: [1 7], Total reward: -513, Step reward: 0, Episode: 3\n",
      "Agent position: [4 5], Target position: [1 7], Total reward: -514, Step reward: -1, Episode: 3\n",
      "Agent position: [3 5], Target position: [1 7], Total reward: -514, Step reward: 0, Episode: 3\n",
      "Agent position: [4 5], Target position: [1 7], Total reward: -515, Step reward: -1, Episode: 3\n",
      "Agent position: [4 4], Target position: [1 7], Total reward: -516, Step reward: -1, Episode: 3\n",
      "Agent position: [4 5], Target position: [1 7], Total reward: -517, Step reward: -1, Episode: 3\n",
      "Agent position: [4 4], Target position: [1 7], Total reward: -518, Step reward: -1, Episode: 3\n",
      "Agent position: [3 4], Target position: [1 7], Total reward: -519, Step reward: -1, Episode: 3\n",
      "Agent position: [2 4], Target position: [1 7], Total reward: -519, Step reward: 0, Episode: 3\n",
      "Agent position: [1 4], Target position: [1 7], Total reward: -519, Step reward: 0, Episode: 3\n",
      "Agent position: [1 5], Target position: [1 7], Total reward: -519, Step reward: 0, Episode: 3\n",
      "Agent position: [2 5], Target position: [1 7], Total reward: -519, Step reward: 0, Episode: 3\n",
      "Agent position: [1 5], Target position: [1 7], Total reward: -519, Step reward: 0, Episode: 3\n",
      "Agent position: [2 5], Target position: [1 7], Total reward: -519, Step reward: 0, Episode: 3\n",
      "Agent position: [2 6], Target position: [1 7], Total reward: -519, Step reward: 0, Episode: 3\n",
      "Agent position: [2 7], Target position: [1 7], Total reward: -518, Step reward: 1, Episode: 3\n",
      "Agent position: [2 6], Target position: [1 7], Total reward: -518, Step reward: 0, Episode: 3\n",
      "Agent position: [2 7], Target position: [1 7], Total reward: -517, Step reward: 1, Episode: 3\n",
      "Agent position: [2 8], Target position: [1 7], Total reward: -517, Step reward: 0, Episode: 3\n",
      "Agent position: [2 9], Target position: [1 7], Total reward: -517, Step reward: 0, Episode: 3\n",
      "Agent position: [1 9], Target position: [1 7], Total reward: -517, Step reward: 0, Episode: 3\n",
      "Agent position: [0 9], Target position: [1 7], Total reward: -517, Step reward: 0, Episode: 3\n",
      "Agent position: [0 9], Target position: [1 7], Total reward: -526, Step reward: -9, Episode: 3\n",
      "Agent position: [0 9], Target position: [1 7], Total reward: -535, Step reward: -9, Episode: 3\n",
      "Agent position: [0 8], Target position: [1 7], Total reward: -535, Step reward: 0, Episode: 3\n",
      "Agent position: [0 7], Target position: [1 7], Total reward: -534, Step reward: 1, Episode: 3\n",
      "Agent position: [0 8], Target position: [1 7], Total reward: -534, Step reward: 0, Episode: 3\n",
      "Agent position: [0 9], Target position: [1 7], Total reward: -534, Step reward: 0, Episode: 3\n",
      "Agent position: [0 8], Target position: [1 7], Total reward: -534, Step reward: 0, Episode: 3\n",
      "Agent position: [0 7], Target position: [1 7], Total reward: -533, Step reward: 1, Episode: 3\n",
      "Agent position: [0 7], Target position: [1 7], Total reward: -541, Step reward: -8, Episode: 3\n",
      "Agent position: [1 7], Target position: [1 7], Total reward: -540, Step reward: 1, Episode: 3\n",
      "Agent position: [1 3], Target position: [2 1], Total reward: 0, Step reward: 0, Episode: 4\n",
      "Agent position: [1 2], Target position: [2 1], Total reward: 0, Step reward: 0, Episode: 4\n",
      "Agent position: [1 3], Target position: [2 1], Total reward: 0, Step reward: 0, Episode: 4\n",
      "Agent position: [1 2], Target position: [2 1], Total reward: 0, Step reward: 0, Episode: 4\n",
      "Agent position: [0 2], Target position: [2 1], Total reward: 0, Step reward: 0, Episode: 4\n",
      "Agent position: [0 3], Target position: [2 1], Total reward: 0, Step reward: 0, Episode: 4\n",
      "Agent position: [0 2], Target position: [2 1], Total reward: 0, Step reward: 0, Episode: 4\n",
      "Agent position: [0 1], Target position: [2 1], Total reward: 0, Step reward: 0, Episode: 4\n",
      "Agent position: [0 0], Target position: [2 1], Total reward: 0, Step reward: 0, Episode: 4\n",
      "Agent position: [0 1], Target position: [2 1], Total reward: 0, Step reward: 0, Episode: 4\n",
      "Agent position: [0 2], Target position: [2 1], Total reward: 0, Step reward: 0, Episode: 4\n",
      "Agent position: [0 1], Target position: [2 1], Total reward: 0, Step reward: 0, Episode: 4\n",
      "Agent position: [0 1], Target position: [2 1], Total reward: -9, Step reward: -9, Episode: 4\n",
      "Agent position: [0 1], Target position: [2 1], Total reward: -18, Step reward: -9, Episode: 4\n",
      "Agent position: [0 2], Target position: [2 1], Total reward: -18, Step reward: 0, Episode: 4\n",
      "Agent position: [0 2], Target position: [2 1], Total reward: -27, Step reward: -9, Episode: 4\n",
      "Agent position: [0 1], Target position: [2 1], Total reward: -27, Step reward: 0, Episode: 4\n",
      "Agent position: [0 2], Target position: [2 1], Total reward: -27, Step reward: 0, Episode: 4\n",
      "Agent position: [1 2], Target position: [2 1], Total reward: -27, Step reward: 0, Episode: 4\n",
      "Agent position: [2 2], Target position: [2 1], Total reward: -26, Step reward: 1, Episode: 4\n",
      "Agent position: [2 1], Target position: [2 1], Total reward: -25, Step reward: 1, Episode: 4\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Run the enfironment for 20 episodes\n",
    "episodes = 5\n",
    "\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, info = env.step(action)\n",
    "        print(f\"Agent position: {info['agent_position']}, Target position: {info['target_position']}, Total reward: {info['total_reward']}, Step reward: {reward}, Episode: {episode}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
